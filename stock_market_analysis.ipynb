# Amazon Model
import re
import sys
import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

FILE_NAME = "/content/sample_data/amazon.csv"
TARGET = "rating"
EPOCHS = 80
BATCH_SIZE = 32
SAVE_MODEL = True
RANDOM_STATE = 42

def to_float_price(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float)): return float(x)
    s = str(x).strip()
    s = re.sub(r"[^\d\.\-]", "", s)
    return float(s) if s else np.nan

def to_float_percent(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float)): return float(x)
    s = str(x).replace("%","").strip()
    s = re.sub(r"[^\d\.\-]", "", s)
    return float(s) if s else np.nan

def to_float_generic(x):
    if pd.isna(x): return np.nan
    if isinstance(x, (int, float)): return float(x)
    s = re.sub(r"[^\d\.\-]", "", str(x))
    return float(s) if s else np.nan

# Load dataset
if not os.path.exists(FILE_NAME):
    raise FileNotFoundError(f"File not found: {FILE_NAME}")

df = pd.read_csv(FILE_NAME)
print("Dataset Loaded Successfully")
print("Columns:", df.columns.tolist())

if TARGET not in df.columns:
    raise ValueError(f"Target column '{TARGET}' not found")

data = df.copy()

if "discounted_price" in data.columns:
    data["discounted_price"] = data["discounted_price"].apply(to_float_price)
if "actual_price" in data.columns:
    data["actual_price"] = data["actual_price"].apply(to_float_price)
if "discount_percentage" in data.columns:
    data["discount_percentage"] = data["discount_percentage"].apply(to_float_percent)
if "rating_count" in data.columns:
    data["rating_count"] = data["rating_count"].apply(to_float_generic)

data[TARGET] = data[TARGET].apply(to_float_generic)

initial_len = len(data)
data = data.dropna(subset=[TARGET])
print(f"Dropped {initial_len - len(data)} rows with missing target")

numeric_candidates = ["discounted_price", "actual_price", "discount_percentage", "rating_count"]
numeric_features = [c for c in numeric_candidates if c in data.columns]
print("Numeric features used:", numeric_features)

cat_features = []
if "category" in data.columns:
    cat_features.append("category")

MAX_CATEGORIES = 40
if "category" in cat_features:
    top_cats = data["category"].value_counts().nlargest(MAX_CATEGORIES).index
    data["category"] = data["category"].where(data["category"].isin(top_cats), "OTHER")
    print("Category unique after top-K mapping:", data["category"].nunique())

features = numeric_features + cat_features
if not features:
    raise ValueError("No usable features found.")

X = data[features].copy()
y = data[TARGET].astype(float).copy()

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", MinMaxScaler())
])

if cat_features:
    cat_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="constant", fill_value="UNKNOWN")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))  # UPDATED
    ])

transformers = [("num", numeric_transformer, numeric_features)]
if cat_features:
    transformers.append(("cat", cat_transformer, cat_features))

preprocessor = ColumnTransformer(transformers=transformers, remainder="drop", sparse_threshold=0)

X_pre = preprocessor.fit_transform(X)
print("Preprocessed feature shape:", X_pre.shape)

X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size=0.2, random_state=RANDOM_STATE)
print("Train / Test sizes:", X_train.shape[0], X_test.shape[0])

USE_TF = True
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Dropout
    print("TensorFlow available. Training NN...")
except Exception:
    USE_TF = False
    print("TensorFlow unavailable. Switching to sklearn MLP.")

if USE_TF:
    model = Sequential([
        Dense(256, activation="relu", input_shape=(X_train.shape[1],)),
        Dropout(0.3),
        Dense(128, activation="relu"),
        Dropout(0.2),
        Dense(64, activation="relu"),
        Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse", metrics=["mae"])
    print(model.summary())

    callbacks = [tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=8, restore_best_weights=True)]
    history = model.fit(X_train, y_train,
                        validation_split=0.1,
                        epochs=EPOCHS,
                        batch_size=BATCH_SIZE,
                        callbacks=callbacks,
                        verbose=2)
    y_pred = model.predict(X_test).flatten()

    if SAVE_MODEL:
        model.save("amazon_rating_model_tf.h5")
        print("Saved TF model -> amazon_rating_model_tf.h5")

else:
    from sklearn.neural_network import MLPRegressor
    mlp = MLPRegressor(hidden_layer_sizes=(200,100), activation="relu",
                       solver="adam", max_iter=EPOCHS, random_state=RANDOM_STATE,
                       verbose=True, early_stopping=True, validation_fraction=0.1)
    mlp.fit(X_train, y_train)
    y_pred = mlp.predict(X_test)

    if SAVE_MODEL:
        import joblib
        joblib.dump(mlp, "amazon_rating_model_sklearn.joblib")
        print("Saved sklearn model -> amazon_rating_model_sklearn.joblib")

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = math.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n=== MODEL PERFORMANCE ===")
print(f"MAE  = {mae:.6f}")
print(f"MSE  = {mse:.6f}")
print(f"RMSE = {rmse:.6f}")
print(f"R2   = {r2:.6f}")

comp = pd.DataFrame({"actual": y_test.values, "predicted": y_pred})
print("\nSample predictions:")
print(comp.head(20).to_string(index=False))

N = min(300, len(y_test))
plt.figure(figsize=(10,4))
plt.plot(range(N), y_test.values[:N], label="actual", marker='.', linewidth=1)
plt.plot(range(N), y_pred[:N], label="predicted", marker='.', linewidth=1)
plt.title("Actual vs Predicted Ratings")
plt.legend()
plt.tight_layout()
plt.show()

print("\nDone.")
