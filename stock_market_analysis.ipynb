{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Share Market & Amazon Product Rating Analysis Notebook\n",
    "This notebook performs:\n",
    "1. Amazon product rating prediction using a neural network.\n",
    "2. Stock market dataset loading, preprocessing, and basic analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Amazon Product Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "FILE_NAME = \"/content/sample_data/amazon.csv\"  # update path if needed\n",
    "TARGET = \"rating\"\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 32\n",
    "SAVE_MODEL = True\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def to_float_price(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = str(x).strip()\n",
    "    s = re.sub(r\"[^\\d\\.\\-]\", \"\", s)\n",
    "    return float(s) if s else np.nan\n",
    "\n",
    "def to_float_percent(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = str(x).replace(\"%\",\"").strip()\n",
    "    s = re.sub(r\"[^\\d\\.\\-]\", \"\", s)\n",
    "    return float(s) if s else np.nan\n",
    "\n",
    "def to_float_generic(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, (int, float)): return float(x)\n",
    "    s = re.sub(r\"[^\\d\\.\\-]\", \"\", str(x))\n",
    "    return float(s) if s else np.nan\n",
    "\n",
    "# Load dataset\n",
    "if not os.path.exists(FILE_NAME):\n",
    "    raise FileNotFoundError(f\"File not found: {FILE_NAME}\")\n",
    "\n",
    "df = pd.read_csv(FILE_NAME)\n",
    "print(\"Dataset Loaded Successfully\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET}' not found\")\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "if \"discounted_price\" in data.columns:\n",
    "    data[\"discounted_price\"] = data[\"discounted_price\"].apply(to_float_price)\n",
    "if \"actual_price\" in data.columns:\n",
    "    data[\"actual_price\"] = data[\"actual_price\"].apply(to_float_price)\n",
    "if \"discount_percentage\" in data.columns:\n",
    "    data[\"discount_percentage\"] = data[\"discount_percentage\"].apply(to_float_percent)\n",
    "if \"rating_count\" in data.columns:\n",
    "    data[\"rating_count\"] = data[\"rating_count\"].apply(to_float_generic)\n",
    "\n",
    "data[TARGET] = data[TARGET].apply(to_float_generic)\n",
    "\n",
    "initial_len = len(data)\n",
    "data = data.dropna(subset=[TARGET])\n",
    "print(f\"Dropped {initial_len - len(data)} rows with missing target\")\n",
    "\n",
    "numeric_candidates = [\"discounted_price\", \"actual_price\", \"discount_percentage\", \"rating_count\"]\n",
    "numeric_features = [c for c in numeric_candidates if c in data.columns]\n",
    "print(\"Numeric features used:\", numeric_features)\n",
    "\n",
    "cat_features = []\n",
    "if \"category\" in data.columns:\n",
    "    cat_features.append(\"category\")\n",
    "\n",
    "MAX_CATEGORIES = 40\n",
    "if \"category\" in cat_features:\n",
    "    top_cats = data[\"category\"].value_counts().nlargest(MAX_CATEGORIES).index\n",
    "    data[\"category\"] = data[\"category\"].where(data[\"category\"].isin(top_cats), \"OTHER\")\n",
    "    print(\"Category unique after top-K mapping:\", data[\"category\"].nunique())\n",
    "\n",
    "features = numeric_features + cat_features\n",
    "if not features:\n",
    "    raise ValueError(\"No usable features found.\")\n",
    "\n",
    "X = data[features].copy()\n",
    "y = data[TARGET].astype(float).copy()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "if cat_features:\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"UNKNOWN\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "transformers = [(\"num\", numeric_transformer, numeric_features)]\n",
    "if cat_features:\n",
    "    transformers.append((\"cat\", cat_transformer, cat_features))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers, remainder=\"drop\", sparse_threshold=0)\n",
    "\n",
    "X_pre = preprocessor.fit_transform(X)\n",
    "print(\"Preprocessed feature shape:\", X_pre.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(\"Train / Test sizes:\", X_train.shape[0], X_test.shape[0])\n",
    "\n",
    "# TensorFlow Neural Network\n",
    "USE_TF = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "except Exception:\n",
    "    USE_TF = False\n",
    "    print(\"TensorFlow unavailable. Switching to sklearn MLP.\")\n",
    "\n",
    "if USE_TF:\n",
    "    model = Sequential([\n",
    "        Dense(256, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=8, restore_best_weights=True)]\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=0.1,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=2)\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    if SAVE_MODEL:\n",
    "        model.save(\"amazon_rating_model_tf.h5\")\n",
    "        print(\"Saved TF model -> amazon_rating_model_tf.h5\")\n",
    "else:\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(200,100), activation=\"relu\",\n",
    "                       solver=\"adam\", max_iter=EPOCHS, random_state=RANDOM_STATE,\n",
    "                       verbose=True, early_stopping=True, validation_fraction=0.1)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    if SAVE_MODEL:\n",
    "        import joblib\n",
    "        joblib.dump(mlp, \"amazon_rating_model_sklearn.joblib\")\n",
    "        print(\"Saved sklearn model -> amazon_rating_model_sklearn.joblib\")\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n=== AMAZON MODEL PERFORMANCE ===\")\n",
    "print(f\"MAE  = {mae:.6f}\")\n",
    "print(f\"MSE  = {mse:.6f}\")\n",
    "print(f\"RMSE = {rmse:.6f}\")\n",
    "print(f\"R2   = {r2:.6f}\")\n",
    "\n",
    "# Sample Predictions\n",
    "comp = pd.DataFrame({\"actual\": y_test.values, \"predicted\": y_pred})\n",
    "print(comp.head(10))\n",
    "\n",
    "# Plot\n",
    "N = min(300, len(y_test))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(range(N), y_test.values[:N], label=\"actual\", marker='.', linewidth=1)\n",
    "plt.plot(range(N), y_pred[:N], label=\"predicted\", marker='.', linewidth=1)\n",
    "plt.title(\"Actual vs Predicted Ratings\")\n",
    "plt.legend()\n",
    "plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Stock Market Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Replace with your stock market dataset path\n",
    "STOCK_FILE = \"/content/sample_data/stock_market.csv\"\n",
    "\n",
    "if not os.path.exists(STOCK_FILE):\n",
    "    raise FileNotFoundError(f\"Stock market dataset not found: {STOCK_FILE}\")\n",
    "\n",
    "stock_df = pd.read_csv(STOCK_FILE)\n",
    "print(\"Stock dataset loaded successfully\")\n",
    "print(stock_df.head())\n",
    "\n",
    "# Basic info\n",
    "print(stock_df.info())\n",
    "\n",
    "# Convert date column if exists\n",
    "if 'Date' in stock_df.columns:\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "    stock_df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Basic stats\n",
    "print(stock_df.describe())\n",
    "\n",
    "# Plot Close price over time if exists\n",
    "if 'Close' in stock_df.columns:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(stock_df['Date'], stock_df['Close'], label='Close Price')\n",
    "    plt.title('Stock Close Price Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Compute returns if 'Close' exists\n",
    "if 'Close' in stock_df.columns:\n",
    "    stock_df['Returns'] = stock_df['Close'].pct_change()\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(stock_df['Date'], stock_df['Returns'], label='Daily Returns')\n",
    "    plt.title('Daily Returns')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(stock_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Stock Market Feature Correlations')\n",
    "plt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

