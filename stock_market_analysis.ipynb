# weather_forecast_mlp.py
# Requirements: pandas, numpy, scikit-learn, matplotlib
# Run: python weather_forecast_mlp.py
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt

file_path = "/mnt/data/seattle-weather.csv"
if not os.path.exists(file_path):
    raise FileNotFoundError(f"File not found: {file_path}")

# --- Load and inspect ---
df = pd.read_csv(file_path)
print("Columns:", df.columns.tolist())
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print("Numeric columns:", numeric_cols)
if len(numeric_cols) == 0:
    raise ValueError("No numeric columns to predict. Provide numeric weather fields.")

# --- Select target (modify if needed) ---
preferred_targets = ['temp_max', 'max_temp', 'Temperature', 'temp', 'TMAX', 'tmax', 'temp_mean', 'temp_avg']
target_col = None
for t in preferred_targets:
    if t in numeric_cols:
        target_col = t
        break
if target_col is None:
    target_col = numeric_cols[0]   # fallback
print("Selected target column:", target_col)

# --- Preprocess numeric data (simple imputation + scaling) ---
df_numeric = df[numeric_cols].copy().interpolate().ffill().bfill()
scaler = StandardScaler()
scaled = scaler.fit_transform(df_numeric.values)
scaled_df = pd.DataFrame(scaled, columns=df_numeric.columns)

# --- Create sequences (time-window -> flattened vector for MLP) ---
LOOKBACK = 30  # number of past days to use
def create_flat_sequences(data, target_column, lookback=30):
    X, y = [], []
    cols = list(data.columns)
    target_idx = cols.index(target_column)
    for i in range(len(data) - lookback):
        seq = data.iloc[i:i+lookback].values.flatten()
        X.append(seq)
        y.append(data.iloc[i+lookback, target_idx])
    return np.array(X), np.array(y)

X, y = create_flat_sequences(scaled_df, target_col, LOOKBACK)
print("Sequence shapes:", X.shape, y.shape)

# --- Train/val/test split ---
n = len(X)
train_end = int(n * 0.7)
val_end = int(n * 0.85)
X_train, y_train = X[:train_end], y[:train_end]
X_val, y_val = X[train_end:val_end], y[train_end:val_end]
X_test, y_test = X[val_end:], y[val_end:]
print("Split sizes (train/val/test):", X_train.shape[0], X_val.shape[0], X_test.shape[0])

# --- MLP model (uses max_iter as epochs) ---
EPOCHS = 100        # <-- set this to any number N you want
mlp = MLPRegressor(
    hidden_layer_sizes=(200, 100),
    activation='relu',
    solver='adam',
    max_iter=EPOCHS,
    early_stopping=True,  # will use validation fraction to stop early
    validation_fraction=len(X_val)/(len(X_train)+len(X_val)),
    n_iter_no_change=10,
    random_state=42,
    verbose=True
)

# Train
mlp.fit(X_train, y_train)

# Predict and invert scaling for target
target_index = list(df_numeric.columns).index(target_col)
target_mean = scaler.mean_[target_index]
target_scale = scaler.scale_[target_index]

y_test_orig = y_test * target_scale + target_mean
y_pred_scaled = mlp.predict(X_test)
y_pred_orig = y_pred_scaled * target_scale + target_mean

# Metrics
mae = mean_absolute_error(y_test_orig, y_pred_orig)
mse = mean_squared_error(y_test_orig, y_pred_orig)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_orig, y_pred_orig)

print("\nTest metrics (original scale):")
print(f"MAE:  {mae:.4f}")
print(f"MSE:  {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R2:   {r2:.4f}")

# Plots
plt.figure(figsize=(10,4))
plt.plot(y_test_orig[:200], label='actual')
plt.plot(y_pred_orig[:200], label='predicted')
plt.legend()
plt.title(f'Predicted vs Actual ({target_col}) - first 200')
plt.show()

# Show top comparisons
comp = pd.DataFrame({'actual': y_test_orig[:20], 'predicted': y_pred_orig[:20]})
print(comp.to_string(index=False))

print("\nTo change epochs: set EPOCHS = <N> and re-run. For reproducible experiments, vary only EPOCHS or model params.")

